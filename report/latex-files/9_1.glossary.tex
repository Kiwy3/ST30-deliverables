%\makeglossaries
%general
\newacronym{bonus}{BONUS}{Big Optimization aNd Ultra-Scale computing}
\newacronym{inria}{INRIA}{National Research Institute for Computer Science and Automation,}
\newacronym{utt}{UTT}{University of Technology of Troyes}
\newacronym{sota}{SOTA}{State-of-the-art}
\newacronym{flops}{FLOPS}{Floating-Point Operations per Second}
\newacronym{ai}{AI}{Artifical Intelligence}
\newacronym{pepr}{PEPR}{Priority Research Program and Equipment}

%chap 2.1
\newacronym{llm}{LLM}{Large Language Models}
\newacronym{dnn}{DNN}{Deep Neural Networks}
\newacronym{mha}{MHA}{Multi-Head Attention}
\newacronym{ann}{ANN}{Artificial Neural Networks}
\newacronym{nn}{NN}{Neural Networks}
\newacronym{nlp}{NLP}{Natural Language Processing}
\newacronym{gpt}{GPT}{Generative Pre-Trained}
\newacronym{sgd}{SGD}{Stochastic Gradient Descent}
\newacronym{adam}{Adam}{Adaptive Moment Estimation}
\newacronym{lstm}{LTSM}{Long Short-Term Memory}
\newacronym{peft}{PEFT}{Parameter Efficient Fine-Tuning}
\newacronym{lora}{LoRA}{Low Rank Adaptation}
\newacronym{mse}{MSE}{Mean-Squared Error}
\newacronym{mlp}{MLP}{Multi-Layer Perceptron}
\newacronym{cnn}{CNN}{Convolutional Neural Networks}
\newacronym{vae}{VAE}{Variational Auto-Encoder}


%chap 2.2
\newacronym{bo}{BO}{Bayesian Optimization}
\newacronym{nas}{NAS}{Neural Architecture Search}
\newacronym{hpo}{HPO}{Hyper-Parameter Optimization}
\newacronym{automl}{Auto-ML}{Automated Machine Learning}
\newacronym{autodnn}{Auto-DNN}{Automated Deep Neural Networks}
\newacronym{mvop}{MVOP}{Mixed Variable-size Optimization Problem}
\newacronym{ml}{ML}{Machine Learning}
\newacronym{gs}{GS}{Grid Search}
\newacronym{rs}{RS}{Random Search}
\newacronym{ea}{EA}{Evolutionnary Algorithms}
\newacronym{ga}{GA}{Genetic Algorithms}
\newacronym{ils}{ILS}{Iterated Local Search}
\newacronym{sa}{SA}{Simulated Annealing}
\newacronym{pbo}{PBO}{Partition Based Optimization}
\newacronym{smbo}{SMBO}{Surrogate-Model Based Optimization}
\newacronym{soo}{SOO}{Simultaneous Optimistic Optimization}
\newacronym{fda}{FDA}{Fractal Decomposition Algorithm}
\newacronym{direct}{DIRECT}{DIviding RECTangle}
\newacronym{gp}{GP}{Gaussian Process}
\newacronym{gpu}{GPU}{Graphics Processing Unit}
\newacronym{hpc}{HPC}{High Performance Computing}
\newacronym{poc}{POC}{Proof-of-Concept}
\newacronym{qc}{QC}{Quality Control}
\newacronym{scm}{SCM}{Supply Chain Management}

\newacronym{dp}{DP}{Data Parallel}
\newacronym{ddp}{DDP}{Distributed Data Parallel}
\newacronym{fsdp}{FSDP}{Fully-Sharded Data Parallel}

% Chap 3
\newacronym{adamw}{AdamW}{Adaptive Moment Estimation with Weight Decay}
\newacronym{cli}{CLI}{Command Line Interface}
\newacronym{mcq}{MCQ}{Multi-Choice Question}
\newacronym{lhs}{LHS}{Latin Hypercube Sampling}
\newacronym{bamsoo}{BaMSOO}{Bayesian Multi Scale Optimistic Optimization}
\newacronym{mcts}{MCTS}{Monte Carlo Tree Search}
\newacronym{ucb}{$\mathcal {UCB}$}{Upper Confidence Bound}
\newacronym{lcb}{LCB}{Lower Confidence Bound}
\newacronym{oop}{OOP}{Object Oriented Programming}

% Chap 3
\newacronym{bogp}{BO-GP}{Bayesian Optimization using Gaussian Process}
\newacronym{ei}{EI}{Expected Improvement}

% Glossary
\newglossaryentry{transformer}
{
    name=transformer,
    plural=transformers,
    description={Neural networks layers type using attention mechanisms}
}
\newglossaryentry{fine_tuning}
{
    name=fine-tuning,
    description={2nd step of \acrshort{llm} training}
}
\newglossaryentry{ft}
{%#TODO - Rephrase description
    name=fine-tuning,
    description={2nd step of \acrshort{llm} training}
}
\newglossaryentry{pt}
{%#TODO - Rephrase description
    name=pre-training,
    description={1st step of training \acrshort{llm}}
}

\newglossaryentry{instruction-tuning}
{
    name=instruction tuning,
    description={Fine-tuning with Instruction and behavior dataset}
}
\newglossaryentry{hyperparameter}
{
    name=hyperparameter,
    plural=hyperparameters,
    description={Parameters not learned by the model}
}
\newglossaryentry{search_space}
{%#TODO - Rephrase description
    name=search space,
    plural=search spaces,
    description={need to define it}
}

\newglossaryentry{search_strat}
{%#TODO - Rephrase description
    name=search strategy ,
    plural=search strategies,
    description={need to define it}
}

\newglossaryentry{himmelblau}
{%#TODO - Rephrase description
    name=himmelblau ,
    description={well-known non-convex function, equation \ref{eq : himmelblau} }
}

\newglossaryentry{perf_est}
{
    name=performances estimation strategy ,
    plural=performances estimation strategies,
    description={need to define it}
}
\newglossaryentry{pytorch}{
    name = PyTorch,
    description = {Tensor-based framework for machine learning}
}
\newglossaryentry{lightning}{
    name = PyTorch Lightning,
    description = {automated deep learning training framework}
}
\newglossaryentry{litgpt}{
    name = LitGPT,
    description = {PyTorch based framework for training \acrshort{llm}}
}
\newglossaryentry{hf}{
    name = HuggingFace,
    description = {Deep Learning Hub with models and datasets}
}

\newglossaryentry{hs}{
    name = HellaSwag,
    description = {Validation Dataset for LLM Fine Tuning}
}



\newglossaryentry{bb}{
    %#TODO - Rephrase description
    name = black-box objective function, 
    description = {DEFINE}
}

\newglossaryentry{mf}{
    %#TODO - Rephrase description
    name = multi-fidelity, 
    description = {DEFINE}
}

\newglossaryentry{acq_fun}{
    %#TODO - Rephrase description
    name = acquisition function, 
    description = {DEFINE}
}


\newglossaryentry{exascale}{
    %#TODO - Rephrase description
    name = exascale, 
    description = {DEFINE}
}

\newglossaryentry{decoder}{
    %#TODO - Rephrase description
    name = decoder-only, 
    description = {\acrshort{llm} model with only the decoder part of the \gls{transformer}}
}

\newglossaryentry{rank}{
    name = LoRA rank, 
    description = {value used for scaling the reduction of \acrfull{lora}}
}
\newglossaryentry{scale}{
    %#TODO - Rephrase description
    name = LoRA scale, 
    description = {NEED IT}
}
\newglossaryentry{lr}{
    %#TODO - Rephrase description
    name = learning rate, 
    description = {NEED IT}
}
\newglossaryentry{dropout}{
    %#TODO - Rephrase description
    name = dropout probability, 
    plural = dropout,
    description = {NEED IT}
}
\newglossaryentry{decay}{
    %#TODO - Rephrase description
    name = weight decay, 
    description = {NEED IT}
}