\section{Conclusions and Perspectives}
\label{sec:conclusion}

For scenarios with a limited number of evaluations, \acrshort{bo} demonstrated exceptional efficiency, quickly converging to high-performing solutions. In contrast, \acrshort{soo}, constrained by one-dimensional sections and less promising search dynamics, exhibited slower convergence. The hybrid approach, \acrshort{bamsoo}, successfully enhanced the convergence rate of \acrshort{soo} while preserving its inherent parallelism capabilities.

This work pioneers the application of hybrid Bayesian and partition-based optimization for expensive functions, laying the groundwork for scaling the efficiency of Bayesian Optimization to exascale computing environments.

Future research should explore higher-performance architectures, larger models, and expanded datasets to effectively distribute the computational load across supercomputers. Additionally, extending the search space to include hyperparameters such as Adam momentum would provide new opportunities to further refine optimization strategies.
