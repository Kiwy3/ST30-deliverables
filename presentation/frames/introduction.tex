%---------------------------------- Large Language Models -------------------------------
\begin{frame}{Large Language Models}
\begin{columns}
      
    \begin{column}[t]{0.5\textwidth}
    \begin{block}{Summary}
    
        \begin{itemize}
            \item State-of-the-art of Natural Language Processing (NLP) problems
            \item Architecture : Transformers\cite{NIPS2017_3f5ee243} block, mixed with classical layers (MLP, Conv)
        \end{itemize}
            

    \end{block}
    \end{column}
        
    \begin{column}[t]{0.5\textwidth}
    \begin{block}{Self Attention cell}

        \begin{figure}
            \centering
            \input{imgs/dot_prod_att}
            \caption{Scaled dot product attention}
        \end{figure}
    

    \end{block}
    \end{column}
         
\end{columns}
\end{frame}

%---------------------------------- Self attention mecanism -------------------------------

\begin{frame}{mha}
    \begin{figure}
        \centering
        \input{imgs/mha}
        \caption{MHA}
    \end{figure}  
        

    
\end{frame}


%---------------------------------- Self attention mecanism -------------------------------

\begin{frame}{self attention}
    \begin{figure}
        \centering
        \input{imgs/self_attention}
        \caption{self attention mecanism}
    \end{figure}  
        

    
\end{frame}


%---------------------------------- Transformers -------------------------------

\begin{frame}{Pre-training and Fine-tuning}
    \begin{figure}
        \centering
        \input{imgs/pre_training}
        \caption{Pre-training and Fine-tuning generic workflow}
    \end{figure}  
        

    
\end{frame}


%---------------------------------- Fine Tuning Frame -------------------------------
\begin{frame}{Fine Tuning}

   \begin{block}{Instruction Tuning}
       fine-tunes models to follow specific user instructions effectively. Consists of using specific fine-tuning datasets (Alpaca \cite{alpaca}, Databrick's Dolly\cite{DatabricksBlog2023DollyV2})   
    \end{block}



    \begin{block}{Parameters Efficient Fine-Tuning (PEFT)}
    Set of methods aims to reduce the computation cost of fine-tuning. Can change the structure like the 2 following, or just reduce the cost like Quantization (reduce the precision of calculus). These methods are often hyperparameter-dependent.     
    \end{block}
    
    \begin{columns}  
  
        \begin{column}[t]{0.45\textwidth}
        \begin{block}{Low Rank Adaptation (LoRA)\cite{hu2021loralowrankadaptationlarge}}
                   Use of low rank matrices of the weights matrices, which will be the only ones trained, to reduce the cost of gradient computations.  
        \end{block}
        \end{column}
    
        \begin{column}[t]{0.45\textwidth}
        \begin{block}{Adapter Layer}
            Add layer inside the model, and train only these. One con is to add inference for predicting.
            
        \end{block}
        \end{column}
      
    \end{columns}

\end{frame}

%---------------------------------- LoRA -------------------------------
\begin{frame}{Low Rank Adaptation (LoRA)}
    \begin{block}{Principle}
        Merging Fine-tuning layers with pre-trained ones can be written as $W = W_0 + \Delta W$, with $W_0$ the pre-trained weights and $\Delta W$ the fine-tuned ones.         
    \end{block}

    \begin{columns}
        \begin{column}[t]{0.45\textwidth}
        \begin{figure}
            \centering
            %\includegraphics[width=0.5\linewidth]{imgs/lora.png}
            \input{imgs/lora}
            \caption{LoRA Decomposition}
        \end{figure}
            
        \end{column}
        
        \begin{column}[t]{0.3\textwidth}
            \begin{block}{LoRA hyperparameters}
            \begin{itemize}
                \item rank : the common dimension between $A$ and $B$.
                \item alpha : apply a weighting between fine-tuning and pre-trained weights
            \end{itemize}
                
            \end{block}
            
        \end{column}
    \end{columns}
    
\end{frame}

%---------------------------------- Hyper-Parameter Optimization -------------------------------
\begin{frame}[allowframebreaks]{Hyper-Parameter Optimization (HPO)}
    
    \begin{columns}
    
        \begin{column}[t]{0.45\textwidth}
        \begin{block}{Hyper-Parameters}
            In a Deep Learning Context, set of value that the algorithms need to run. Affect the model, the training or the prediction. The hyper-parameters, often called variables, are mixed (i.e. continuous and integers, no categoricals).
        \end{block}
        \end{column}
        
        \begin{column}[t]{0.45\textwidth}
        \begin{block}{Optimization}
            Set of methods to find the best input value to maximize or minimize an objective function. The problem here can be defined as a black-box optimization (i.e. no analytic form), and an expensive one. An evaluation can take hours.
        \end{block}
        \end{column}
         
  \end{columns}

    \vspace{1cm}
  
      \noindent The Hyper-Parameter Optimization field can be defined as the use of Optimization method to hyper-parameter dependent problem, like Deep Learning ones.\\
      Aims are diverses, from obtaining better results, putting humans out of the loop or ensuring reliability.

\framebreak

\begin{block}{Generic workflow}
    \begin{figure}
        \centering
        \includegraphics[width=0.4\linewidth]{imgs/hpo_workflow.png}
        \caption{HPO Workflow}
    \end{figure}

    
\end{block}
\end{frame}