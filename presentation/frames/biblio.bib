%------------------Attention is all you need - 2017 ---------------
@inproceedings{NIPS2017_3f5ee243,
author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
booktitle = {Advances in Neural Information Processing Systems},
editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {},
publisher = {Curran Associates, Inc.},
title = {Attention is All you Need},
url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
volume = {30},
year = {2017}
}

%------------------ GPT4 - 2023 ---------------
@misc{openai2023gpt4,
    title         = {GPT-4 Technical Report},
    author        = {OpenAI},
    year          = {2023},
    month         = {March},
    publisher     = {OpenAI},
    note          = {\url{https://openai.com/research/gpt-4}}
}


%------------------ LLama 3.1 - 2024 ---------------
@misc{touvron2024llama,
    title         = {LLaMA 3: Open and Adaptable Foundation Models},
    author        = {Guillaume Lample and Hugo Touvron and Lucas Beeching and others},
    year          = {2024},
    month         = {July},
    publisher     = {Meta AI},
    note          = {\url{https://github.com/meta-llama/llama3}}
}

%------------------ Alpaca dataset - 2023 ---------------
@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

%------------------ Databricks' Dolly - 2023 ---------------
@online{DatabricksBlog2023DollyV2,
    author    = {Mike Conover and Matt Hayes and Ankit Mathur and Jianwei Xie and Jun Wan and Sam Shah and Ali Ghodsi and Patrick Wendell and Matei Zaharia and Reynold Xin},
    title     = {Free Dolly: Introducing the World's First Truly Open Instruction-Tuned LLM},
    year      = {2023},
    url       = {https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm},
    urldate   = {2023-06-30}
}

%------------------ Low Rank Adaptation - 2021 ---------------
@misc{hu2021loralowrankadaptationlarge,
title={LoRA: Low-Rank Adaptation of Large Language Models},
author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
year={2021},
eprint={2106.09685},
archivePrefix={arXiv},
primaryClass={cs.CL},
url={https://arxiv.org/abs/2106.09685},
}

%------------------ DiRect - 1993 ---------------
@article{jones1993direct,
    author    = {Donald R. Jones and Cary D. Perttunen and Bruce E. Stuckman},
    title     = {Lipschitzian Optimization Without the Lipschitz Constant},
    journal   = {Journal of Optimization Theory and Applications},
    year      = {1993},
    volume    = {79},
    number    = {1},
    pages     = {157--181},
    publisher = {Springer}
}

%------------------ Fractals - 2022 ---------------
@unpublished{firmin:hal-04474444,
TITLE = {{A fractal-based decomposition framework for continuous optimization}},
AUTHOR = {Firmin, Thomas and Talbi, El-Ghazali},
URL = {https://hal.science/hal-04474444},
NOTE = {working paper or preprint},
YEAR = {2022},
MONTH = Jul,
KEYWORDS = {Continuous optimization ; Metaheuristic ; High-dimensional optimization ; Decomposition ; Fractal ; Tree search},
PDF = {https://hal.science/hal-04474444v1/file/fractal_decomposition_jogo-6.pdf},
HAL_ID = {hal-04474444},
HAL_VERSION = {v1},
}

%------------------ SOO - 2011 ---------------
@inproceedings{munos2011soo,
    author    = {RÃ©mi Munos},
    title     = {Optimistic Optimization of a Deterministic Function without the Knowledge of its Smoothness},
    booktitle = {Advances in Neural Information Processing Systems 24 (NeurIPS)},
    year      = {2011},
    pages     = {783--791}
}

%------------------ BaMSOO - 2014 ---------------
@article{wang2014bamsoo,
  title={Bayesian multi-scale optimistic optimization},
  author={Wang, Ziyu and Shakibi, Babak and Jin, Lin and de Freitas, Nando},
  journal={Proceedings of the 17th International Conference on Artificial Intelligence and Statistics},
  volume={33},
  pages={1005--1013},
  year={2014},
  publisher={Proceedings of Machine Learning Research}
}

%------------------ GLUE - 2018 ---------------
@inproceedings{wang2018glue,
  title={GLUE: A multi-task benchmark and analysis platform for natural language understanding},
  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},
  booktitle={Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
  pages={353--355},
  year={2018}
}

%------------------ MMLU - 2021 ---------------
@article{hendrycks2021mmlu,
  title={Measuring Massive Multitask Language Understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300},
  year={2020}
}




%------------------ BOHB - 2018 ---------------
@article{DBLP:journals/corr/abs-1807-01774,
  author       = {Stefan Falkner and
                  Aaron Klein and
                  Frank Hutter},
  title        = {{BOHB:} Robust and Efficient Hyperparameter Optimization at Scale},
  journal      = {CoRR},
  volume       = {abs/1807.01774},
  year         = {2018},
  url          = {http://arxiv.org/abs/1807.01774},
  eprinttype    = {arXiv},
  eprint       = {1807.01774},
  timestamp    = {Mon, 13 Aug 2018 16:47:48 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1807-01774.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

