%---------------------------------- Problem definition -------------------------------
\begin{frame}{Problem Definition}
   

    \begin{columns}
    
        \begin{column}[t]{0.45\textwidth}
            

            \begin{block}{Problem Formulation}
                The HPO problem can be defined as 
                \begin{equation}
                \eta^* \in \arg\min_{\eta \in \mathcal{H}} \mathcal{F}(\eta) 
                \end{equation}
            \end{block}

            This function can be characterized as an \large\textbf{expensive, mixed-variable, noisy, blackbox} function.
            \end{column}
        
        \begin{column}[t]{0.45\textwidth}
            \begin{block}{3 phases of an optimization problem}
                \begin{itemize}
                    \item \textbf{Search Space $\mathcal{H}$} : all variables and how to handle them
                    \item \textbf{Search Strategy $\arg\min$} : how to search for the minimum of the function
                    \item \textbf{Performance Evaluation Strategy $\mathcal{F}(.)$} : how to evaluate a given solution
                \end{itemize}
            \end{block}

        \end{column}
         
  \end{columns}
\end{frame}


%------------------------------------ Search Space ---------------------------
\begin{frame}{Search Space}


    \begin{block}{Hyperparameters}
    
        \begin{table}[h!]
            \centering
            \begin{tabular}{|c|c|c|c|c|}
                \hline
                \multirow{2}{*}{\textbf{ Hyperparameters }} & \multicolumn{2}{|c|}{\textbf{Optimization range}} &\multirow{2}{*}{\textbf{ Type }}& \multirow{2}{*}{\textbf{ Conversion }} \\
                \cline{2-3}
                 & \textbf{ Lower Bound } & \textbf{ Upper Bound } & & \\
                \hline
                \textbf{Learning Rate} & $-10$ & $-1$ & log. & $f(x) = 10^{x}$ \\
                \hline
                \textbf{LoRA Rank} & 1 & 64 &int. &$f(x) = \text{round}(x)$ \\
                \hline
                \textbf{LoRA scale ($\alpha$)} &1 & 64 & int. &$f(x) = \text{round}(x)$ \\
                \hline
                \textbf{LoRA Dropout} & 0 & 0.5 & cont.& $f(x) = x$ \\
                \hline
                \textbf{Weight Decay} & $-3$ & $-1$ &log.& $f(x) = 10^{x}$  \\
                \hline
            \end{tabular}
            \caption{Summary of Hyperparameter Search Space}
            \label{tab:hyperparam_table}
        \end{table}
        
    \end{block}
    
    
    \begin{itemize}
        \item Conversion and naming convention is taken from LitGPT framework.
        \item Variable conversion for handling mixed-variables with continuous algorithms
        \item No \textit{A-priori} knowledge on hyperparameters importance
    \end{itemize}
\end{frame}


%---------------------------------- Search Strategy  -------------------------------
\begin{frame}{Search Strategy}
    Algorithms for LLM HPO are \textit{Global Optimization} algorithms. Can be classified as : 

    \begin{itemize}
        \item \textbf{Exploratory}(GS, Random Search, LHS) : sample the search space\\ \quad no exploitation, give a lower bound
        \item \textbf{Metaheuristics} (Genetic Algorithm, ILS, PSO) : bio-inspired heuristics \\ \quad evaluation greedy, cannot be used for expensive function
        \item \textbf{Surrogate-Model based Optimization} (Bayesian Optimization with Gaussian Process, TS) : \\ \quad Use a surrogate to enhance exploitation - innate sequential nature, strong exploitation
        \item \textbf{Partition-Based Optimization}(FDA, SOO, DiRect) : partition the search space \\ \quad massively parallel, slow convergence
    \end{itemize}


\end{frame}

%---------------------------------- Performance Evaluation Strategy -------------------------------

\begin{frame}{Performance Evaluation Strategy}
    \begin{block}{Evaluation context}
    In this part, there are many options, like the number of epochs (if not an hyperparameters), the precision of the model, the datasets of training or evaluation. 
        
    \end{block}
    \begin{block}{Objective function}
        2 ways to evaluate LLM Fine-Tuning : 
        \begin{itemize}
            \item \textbf{Loss (validation/test)} : dataset and model dependant, difficult to compare to other models.
            \item \textbf{Accuracy on Benchmark dataset (GLUE, MMLU)} : can be used to compare to other models throughout the training. 
        \end{itemize}
    \end{block}

    \begin{block}{Complementary approaches}
        \begin{itemize}
            \item Multi-fidelity : reduce the cost and the reliability of early evaluations. (ex : BOHB algorithm)
        \end{itemize}
        
    \end{block}
    
\end{frame}