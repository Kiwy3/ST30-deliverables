\begin{frame}{Conclusions}

\begin{itemize}
    \item With limited budget, BO-GP demonstrated exceptional efficiency, quickly converging to high-performing solutions. 
    \item BaMSOO succed to fasten SOO convergence by preventing unpromising evaluations.
    \item Lay groundwork for using PBO algorithms, enhance with BO-GP to deal with LLM Fine-Tuning
\end{itemize}


\end{frame}

\begin{frame}{Perspectives}

    \begin{columns}
        \begin{column}{0.45\textwidth}

            \begin{block}{Extend experiments on the application}
                \begin{itemize}
                    \item Extend search space (add hyperparameters, bigger range...)
                    \item Use more models/datasets
                    \item Make a distributed implementation
                \end{itemize}
            \end{block}
        \end{column}

        \begin{column}{0.45\textwidth}
            \begin{block}{Generalization of BaMSOO Hybridization}

                \begin{itemize}
                    \item explore parallelism of BO-GP based algorithms
                    \item Global Framework of \textit{Parallel Bayesian-enhanced Fractals Optimization} 
                \end{itemize}
            \end{block}
        \end{column}

    \end{columns}
    
\end{frame}