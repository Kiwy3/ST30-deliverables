%---------------------------------- Large Language Models -------------------------------
\begin{frame}{Large Language Models}
\begin{columns}
      
    \begin{column}[t]{0.4\textwidth}
    \begin{block}{Summary}
    
        \begin{itemize}
            \item State-of-the-art of Natural Language Processing (NLP) problems
            \item Architecture : Transformers\footnote{Vaswani et al., « Attention is All you Need ».} block, mixed with classical layers (MLP, Conv)
            \item Huge size : Billions of parameters (1B to 405B for Llama 3)
            \item 2 phases of training : pre-training and \textbf{fine-tuning}
        \end{itemize}
            

    \end{block}
    \end{column}
        
    \begin{column}[t]{0.55\textwidth}
    \begin{block}{Self Attention }

        \begin{figure}
            \centering
            \input{imgs/self_attention.tex}
            \caption{Self Attention mecanism illustration}
        \end{figure}
    
        Self attention is the key of LLM, used to compute the context of each token.
    \end{block}  
    \end{column}
         
\end{columns}
\end{frame}

%---------------------------------- Fine-tuning Workflow -------------------------------

\begin{frame}{Fine-Tuning}

    Following a first phase of pre-training, Fine-tuning is used to correct behavior or add in-domain data to a model, with limited resources. 


    \begin{figure}
        \centering
        \resizebox{\textwidth}{!}{
            \input{imgs/pre_training}
        }
        \caption{Pre-training and Fine-tuning generic workflow}
    \end{figure}  
        

    
\end{frame}

%---------------------------------- Fine Tuning Frame -------------------------------
\begin{frame}{Parameters Efficient Fine-Tuning (PEFT)}
    Set of methods aims to reduce the computation cost of fine-tuning. 2 main approaches : \textit{Additive} and \textbf{reparametrization}.
    
    \begin{columns}  
  
        \begin{column}[t]{0.45\textwidth}
        \begin{block}{Reparametrization}
            Use lower-cost proxy as trainable weights, and merge at the end. e.g. : LoRA and derived methods
        \end{block}
        \end{column}
    
        \begin{column}[t]{0.45\textwidth}
        \begin{block}{Additive}
            Add part of the model, often linear layer, to train these.  One con is to add inference to generation.
            
        \end{block}
        \end{column}
      
    \end{columns}

    \begin{block}{Quantization}
        To reduce further the cost of computing during the training, quantization can also be used. This can be combined with either of precedent approaches. 
        
    \end{block}

\end{frame}



%---------------------------------- LoRA -------------------------------
\begin{frame}{Low Rank Adaptation (LoRA)}
    \begin{block}{Principle}
        Merging Fine-tuning layers with pre-trained ones can be written as $W = W_0 + \Delta W$, with $W_0$ the pre-trained weights and $\Delta W$ the fine-tuned ones. With LoRA, $W=W_0 + \frac{\alpha}{r} B.A$        
    \end{block}

    \begin{columns}
        \begin{column}[t]{0.45\textwidth}
        \begin{figure}
            \centering
            \resizebox{\textwidth}{!}{
                \input{imgs/lora}
            }
            \caption{LoRA Decomposition}
        \end{figure}
            
        \end{column}
        
        \begin{column}[t]{0.3\textwidth}
            \begin{block}{LoRA hyperparameters}
            \begin{itemize}
                \item rank $r$ : the common dimension between $A$ and $B$.
                \item alpha $\alpha$ : apply a weighting between fine-tuning and pre-trained weights
            \end{itemize}
                
            \end{block}
            
        \end{column}
    \end{columns}
    
\end{frame}

%---------------------------------- HPO -------------------------------
\begin{frame}{Hyperparameter Optimization (HPO)}

    \begin{columns}
         
        %%%%%%%%%%%%%%%%%%%%%%%%%% COLONNE DE GAUCHE %%%%%%%%%%%%%%
           \begin{column}{0.3\textwidth} 
           \begin{block}{Objectives}
            \begin{itemize}
                \item Better performance than manual tuning
                \item Ease popularization of the Fine Tuning
            \end{itemize}
            
           \end{block}
    
           \end{column}
               
        %%%%%%%%%%%%%%%%%%%%%%%%% COLONNE DE DROITE %%%%%%%%%%%%%%
           \begin{column}{0.7\textwidth}
            \begin{figure}
                \centering
                \resizebox{\textwidth}{!}{
                    \input{imgs/hpo_workflow.tex}
                }
                \caption{HPO workflow}
           \end{figure}  
           \end{column}
                
       \end{columns}

\end{frame}

%---------------------------------- Review Summary -------------------------------
\begin{frame}{Related Works}
    \begin{figure}
        \resizebox{0.9\textwidth}{!}{
            \input{imgs/summary_review.tex}
        }
        \caption{Summary of links between LLM and Optimization}
    \end{figure}
    
    
\end{frame}